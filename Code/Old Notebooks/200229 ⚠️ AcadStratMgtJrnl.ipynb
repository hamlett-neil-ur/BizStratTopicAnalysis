{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose.\n",
    "\n",
    "Here we collect abstracts and titles from [*Academy of Strategic Management Journal*](https://www.abacademies.org/journals/academy-of-strategic-management-journal-home.html).  This information is to be used as part of an attempt to apply text classification to charting the progression of business strategy.\n",
    "\n",
    "## Approach.\n",
    "\n",
    "Titles and abstracts are available without paywall login. But we have to do this in ***three stages***.  \n",
    "\n",
    "⓵ **Get the URL for the each volume**. We start with the journal's hope page.  Our essential information is embedded in a frame depicted below on the right-hand side of the page. \n",
    "\n",
    "⓶ **Get a list of issue URLs**.  Each volume page contains thumbnail images of individual issues. These include URLs to the individual isses. \n",
    "\n",
    "⓷ **Collect lists of titles**.  Follow each issue's URL to its issue table of contents. The tables of contents contain titles, as well as URLs to pages for individual articles.\n",
    "\n",
    "⓸ **Collect abstracts**.  Abstracts are accessible from individual articles. We have to get the abstracts from these individual-article pages.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools as it\n",
    "import json\n",
    "import io\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use lots of list-comprehension, which drives requests.get operations.\n",
    "# We need to \"throttle\" these, so as to avoid the appearance of a DDoS\n",
    "# attack.  We accomplish this by a get_sleep function.  This function \n",
    "# executes a req.get operation, returning the result, with a one-second\n",
    "# delay.\n",
    "def sleep_get(url, headers):\n",
    "    time.sleep(np.random.uniform(low = 0.5,\n",
    "                                 high = 2.5))\n",
    "    return(req.get(url,\n",
    "                   headers = headers))\n",
    "#\n",
    "# Partition a list into a specified number of bins.  Our inputs\n",
    "# are:\n",
    "# ⧐ parted_list is the list to be partitioned;\n",
    "# ⧐ partition_counts specifies the number of bins into which\n",
    "#   parted_list is divided.\n",
    "# We produce an enumerated dictionary of the list partitions.\n",
    "def partition_list(parted_list, partition_counts):\n",
    "    parted_list = np.sort(np.array(parted_list))\n",
    "    partition_len = int(np.ceil(len(parted_list)/partition_counts))\n",
    "    partitions = [np.array(object = range(partition_len)) + part * partition_len\n",
    "                     for part in range(partition_counts)]\n",
    "    partitions[-1] = np.arange(start = partitions[-1][0],\n",
    "                               stop = parted_list.shape[0])\n",
    "    return dict(enumerate([list(parted_list[part])\n",
    "                             for part in partitions]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "asmjUrl = 'https://www.abacademies.org/journals/'\n",
    "headers = {\n",
    "    'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n",
    "    }\n",
    "asmjHtml = sleep_get(asmjUrl + 'academy-of-strategic-management-journal-home.html',\n",
    "                            headers = headers)\n",
    "asmjSoup = BeautifulSoup(asmjHtml.content, 'lxml')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this issue, all of the issues appear on a single page. We simply have\n",
    "# to get these.\n",
    "\n",
    "asmjTitleAbstract = {volume.find('h4').text : {'issueToc' :  {issue.text : {'href' : issue.attrs.get('href')}\n",
    "                                                for issue in volume.find_all('a')}}\n",
    "                        for volume in asmjSoup.find_all('div', {'class' : 'card-body'})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume 2011, issue Volume 10, Issue 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.abacademies.org/journals/month-december-year-2011-vol-10-issue-2-journal-asmj-past-issue.html'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = np.random.choice(a = list(asmjTitleAbstract.keys()),\n",
    "                          size = 1).item(0)\n",
    "issue = np.random.choice(a = list(asmjTitleAbstract.get(volume).get('issueToc').keys()),\n",
    "                         size = 1).item(0)\n",
    "print(f'Volume {volume}, issue {issue}')\n",
    "asmjUrl + asmjTitleAbstract.get(volume).get('issueToc').get(issue).get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issueToc': {'Volume 10, Issue 2': {'href': 'month-december-year-2011-vol-10-issue-2-journal-asmj-past-issue.html'},\n",
       "  'Volume 10, Issue 1': {'href': 'month-june-year-2011-vol-10-issue-1-journal-asmj-past-issue.html'}}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asmjTitleAbstract.get(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020',\n",
       " '2019',\n",
       " '2018',\n",
       " '2017',\n",
       " '2016',\n",
       " '2015',\n",
       " '2014',\n",
       " '2013',\n",
       " '2012',\n",
       " '2011',\n",
       " '2010',\n",
       " '2009',\n",
       " '2008',\n",
       " '2007',\n",
       " '2006',\n",
       " '2005',\n",
       " '2004',\n",
       " '2003',\n",
       " '2002']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(asmjTitleAbstract.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020': {'issueToc': {'Issue 1': {'href': 'month-february-year-2020-vol-19-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2019': {'issueToc': {'Issue 1': {'href': 'month-february-year-2019-vol-18-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2018': {'issueToc': {'Issue 1': {'href': 'month-february-year-2018-vol-17-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2017': {'issueToc': {'Special Issue 1': {'href': 'https://www.abacademies.org/special-issues/volume-16-special-issue-1.html'}}},\n",
       " '2016': {'issueToc': {'Issue 2': {'href': 'month-september-year-2016-vol-15-issue-2-journal-asmj-past-issue.html'}}},\n",
       " '2015': {'issueToc': {'Issue 1': {'href': 'month-june-year-2015-vol-14-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2014': {'issueToc': {'Issue 1': {'href': 'month-june-year-2014-vol-13-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2013': {'issueToc': {'Issue 1': {'href': 'month-june-year-2013-vol-12-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2012': {'issueToc': {'Issue 1': {'href': 'month-june-year-2012-vol-11-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2011': {'issueToc': {'Issue 1': {'href': 'month-june-year-2011-vol-10-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2010': {'issueToc': {'Issue 1': {'href': 'month-june-year-2010-vol-9-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2009': {'issueToc': {'Issue 1': {'href': 'month-june-year-2009-vol-8-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2008': {'issueToc': {'Issue 1': {'href': 'month-june-year-2008-vol-7-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2007': {'issueToc': {'Issue 1': {'href': 'month-june-year-2007-vol-6-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2006': {'issueToc': {'Issue 1': {'href': 'month-june-year-2006-vol-5-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2005': {'issueToc': {'Issue 1': {'href': 'month-june-year-2005-vol-4-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2004': {'issueToc': {'Issue 1': {'href': 'month-june-year-2004-vol-3-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2003': {'issueToc': {'Issue 1': {'href': 'month-june-year-2003-vol-2-issue-1-journal-asmj-past-issue.html'}}},\n",
       " '2002': {'issueToc': {'Issue 1': {'href': 'month-june-year-2002-vol-1-issue-1-journal-asmj-past-issue.html'}}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asmjTitleAbstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issues are organized by calendar year.  All of the calendar-year linkes are stored in\n",
    "# `a`-taged html tags with class `title expander2 yearExpander`.  Assemble this into \n",
    "# a dictionary.\n",
    "stratOrgTitleAbstr = {calYear.text : {'href' : calYear.attrs.get('href')}\n",
    "                        for calYear in stratOrgUrlSoup.find_all('a', {'class' : 'title expander2 yearExpander'})}\n",
    "\n",
    "\n",
    "stratOrgTitleAbstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect urls for individual-issue ToCs.  Associated with each calendar year we have\n",
    "# a URL to a page with each of the issues. We get an issue label and the URL for its \n",
    "# table of contents.\n",
    "\n",
    "calYearDone = list()\n",
    "calYearMissed = list()\n",
    "for calYear in stratOrgTitleAbstr.keys():\n",
    "    try:\n",
    "        calYearHtml = sleep_get(stratOrgUrl + stratOrgTitleAbstr.get(calYear).get('href'),\n",
    "                                headers = headers)\n",
    "        stratOrgTitleAbstr.get(calYear).update(\n",
    "            {'issueToC' : {issue.find('a').get_text(strip = True) : {'href' : issue.find('a').attrs.get('href')}\n",
    "                                for issue in BeautifulSoup(calYearHtml.content, \"lxml\").find_all('h6')}})\n",
    "        calYearDone.append(calYear)\n",
    "        print('{} success at {}'.format(calYear, \n",
    "                                      datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "    except:\n",
    "        calYearMissed.append(calYear)\n",
    "        print('{} failure at {}'.format(calYear, \n",
    "                                      datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratOrgTitleAbstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDict(baseline, update):\n",
    "    return {key : val\n",
    "               for dictObjs in [baseline,\n",
    "                                update]\n",
    "               for (key, val) in dictObjs}\n",
    "\n",
    "def getIssueArticleTitleAbstr(calYear, issue):\n",
    "    issueHtml = sleep_get(stratOrgTitleAbstr.get(calYear).get('issueToC').get(issue).get('href'),\n",
    "                          headers = headers)\n",
    "    issueSoup = BeautifulSoup(issueHtml.content,\n",
    "                              'lxml').find('form', {'name' : 'frmAbs'})\n",
    "    issueDict = stratOrgTitleAbstr.get(calYear).get('issueToC').get(issue)\n",
    "    issueDict = dict(enumerate([{'title' : article.find('span', {'class' : 'hlFld-Title'})\\\n",
    "                                                  .text\\\n",
    "                                                  .lower(),\n",
    "                                  'published' : article.find('span', {'class' : 'tocEPubDate'})\\\n",
    "                                                       .text\\\n",
    "                                                       .replace('First Published ', ''),\n",
    "                                  'abstrURL' : article.find('div', {'class' : 'abstract-section'})\\\n",
    "                                                      .find('a')\\\n",
    "                                                      .attrs\n",
    "                                                      .get('href')}\n",
    "                                    for article in issueSoup.find_all('td', {'valign' : 'top'})\n",
    "                                    if article.find('span', {'class' : 'hlFld-Title'}) is not None]))\n",
    "    for article in issueDict.keys():\n",
    "        articleDict = issueDict.get(article)\n",
    "        try: \n",
    "            artAbstrHtml = sleep_get(stratOrgUrl + issueDict.get(article).get('abstrURL'),\n",
    "                                     headers = headers)\n",
    "            artAbstrSoup = BeautifulSoup(artAbstrHtml.content,\n",
    "                                         'lxml').find('div', {'class' : 'abstractSection abstractInFull'})\n",
    "            issueDict.get(article).update({'abstract' : artAbstrSoup.text\\\n",
    "                                                                    .lower()})\n",
    "        except:\n",
    "            issueDict.get(article).update({'abstract' : str()})\n",
    "    return issueDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calYear = np.random.choice(a = list(stratOrgTitleAbstr.keys()),\n",
    "                           size = 1).item(0)\n",
    "issue = np.random.choice(a = list(stratOrgTitleAbstr.get(calYear).get('issueToC').keys()),\n",
    "                         size = 1).item(0)\n",
    "print('Calendar Year {}  issue {}\\nURL {} '\\\n",
    "      .format(calYear, issue, stratOrgTitleAbstr.get(calYear).get('issueToC').get(issue).get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for calYear in stratOrgTitleAbstr.keys():\n",
    "    issuesDone = list()\n",
    "    issuesMissed = list()\n",
    "    for issue in stratOrgTitleAbstr.get(calYear).get('issueToC').keys():\n",
    "        try:\n",
    "            stratOrgTitleAbstr.get(calYear)\\\n",
    "                             .get('issueToC')\\\n",
    "                             .get(issue)\\\n",
    "                             .update({'titleAbstr' : getIssueArticleTitleAbstr(calYear, issue)})\n",
    "            issuesDone.append(', '.join([calYear, issue]))\n",
    "            print('{}, {} success at {}'.format(calYear,\n",
    "                                                    issue,\n",
    "                                                    datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "        except:\n",
    "            stratOrgTitleAbstr.get(calYear)\\\n",
    "                             .get('issueToC')\\\n",
    "                             .get(issue)\\\n",
    "                             .update({'titleAbstr' : dict()})\n",
    "            issuesMissed.append(', '.join([calYear, issue]))\n",
    "            print('{}, {} failure at {}'.format(calYear,\n",
    "                                                    issue,\n",
    "                                                    datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "        with io.open('./data/stratOrgTitleAbstract.json', 'w', encoding = 'utf-8') as f:\n",
    "            json.dump(stratOrgTitleAbstr, \n",
    "                      f, \n",
    "                      ensure_ascii = False, \n",
    "                      indent = 4)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratOrgTitleAbstr.get(calYear)\\\n",
    "                 .get('issueToC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
