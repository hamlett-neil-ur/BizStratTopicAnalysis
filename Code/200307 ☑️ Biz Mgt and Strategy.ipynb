{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose.\n",
    "\n",
    "Here we collect abstracts and titles from [*Business Management and Strategy*](http://www.macrothink.org/journal/index.php/bms) magazine, formerly published by the consultancy Booze-Allen-Hamilton.  This information is to be used as part of an attempt to apply text classification to charting the progression of business strategy.\n",
    "\n",
    "## Approach.\n",
    "\n",
    "Titles and abstracts are available without paywall login. But we have to do this in ***three stages***.  \n",
    "\n",
    "⓵ **Get the URL for the each volume**. We start with the journal's hope page.  Our essential information is embedded in a frame depicted below on the right-hand side of the page. \n",
    "\n",
    "⓶ **Get a list of issue URLs**.  Each volume page contains thumbnail images of individual issues. These include URLs to the individual isses. \n",
    "\n",
    "⓷ **Collect lists of titles**.  Follow each issue's URL to its issue table of contents. The tables of contents contain titles, as well as URLs to pages for individual articles.\n",
    "\n",
    "⓸ **Collect abstracts**.  Abstracts are accessible from individual articles. We have to get the abstracts from these individual-article pages.\n",
    "\n",
    "\n",
    "### Running on Azure.\n",
    "\n",
    "If we need to run in Azure, we will need to install ChromeDriver on the Ubuntu host.  This https://www.srcmake.com/home/selenium-python-chromedriver-ubuntu describes the procedure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools as it\n",
    "import json\n",
    "import io\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use lots of list-comprehension, which drives requests.get operations.\n",
    "# We need to \"throttle\" these, so as to avoid the appearance of a DDoS\n",
    "# attack.  We accomplish this by a get_sleep function.  This function \n",
    "# executes a req.get operation, returning the result, with a one-second\n",
    "# delay.\n",
    "def sleep_get(url, headers):\n",
    "    time.sleep(np.random.uniform(low = 1.5,\n",
    "                                 high = 2.75))\n",
    "    return(req.get(url,\n",
    "                   headers = headers))\n",
    "#\n",
    "# Partition a list into a specified number of bins.  Our inputs\n",
    "# are:\n",
    "# ⧐ parted_list is the list to be partitioned;\n",
    "# ⧐ partition_counts specifies the number of bins into which\n",
    "#   parted_list is divided.\n",
    "# We produce an enumerated dictionary of the list partitions.\n",
    "def partition_list(parted_list, partition_counts):\n",
    "    parted_list = np.sort(np.array(parted_list))\n",
    "    partition_len = int(np.ceil(len(parted_list)/partition_counts))\n",
    "    partitions = [np.array(object = range(partition_len)) + part * partition_len\n",
    "                     for part in range(partition_counts)]\n",
    "    partitions[-1] = np.arange(start = partitions[-1][0],\n",
    "                               stop = parted_list.shape[0])\n",
    "    return dict(enumerate([list(parted_list[part])\n",
    "                             for part in partitions]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bizMgtStrat = 'http://www.macrothink.org/journal/index.php/bms'\n",
    "headers = {\n",
    "    'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n",
    "    }\n",
    "# /loi/1932443x Stragic Entrepreneurship Journal\n",
    "# /loi/10970266 Strategic Management Journal\n",
    "bizMgtStratHtml = sleep_get(bizMgtStrat + '/issue/archive',\n",
    "                            headers = headers)\n",
    "bizMgtStratSoup = BeautifulSoup(bizMgtStratHtml.content, \n",
    "                               'lxml').find_all('h4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All published issues are indexed on a common page.  We get the volume and issue information, here.\n",
    "# We look for publication date on the issue pages.\n",
    "volIssue = {issue.text.split(' (')[0] : {'href' : issue.find('a').attrs.get('href')}\n",
    "                    for issue in bizMgtStratSoup }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Issue tables of contents are contained in a block demarcated by labels\n",
    "# `<div id=\"content\">`.  The simple layout allows us to get all of the individual-article\n",
    "# information (except for abstracts) via dictionary comprehension.  Each article is\n",
    "# demarcated by an html label `<div class=\"tocTitle\">`.  The publication date appears in \n",
    "# a header block with a comma-separated field.\n",
    "def getIssueToc(issueUrl):\n",
    "    issueSoup = BeautifulSoup(sleep_get(volIssue.get(issue).get('href'),\n",
    "                                        headers = headers).content,\n",
    "                              'lxml').find('div', {'id' : 'content'})\n",
    "    issueToc = dict(enumerate([{'title' : article.find('a')\n",
    "                                                 .text\n",
    "                                                 .lower(),\n",
    "                      'href' : article.find('a')\n",
    "                                      .attrs\n",
    "                                      .get('href'),\n",
    "                      'pubDate' : issueSoup.find('div', {'id' : 'issueDescription'})\n",
    "                                           .text\n",
    "                                           .split(', ')[-1]\n",
    "                                           .split('\\\\')[0]}\n",
    "                        for article in issueSoup.find_all('div', {'class' : 'tocTitle'})]))\n",
    "    #\n",
    "    # The abstract appears on each article's individual page.\n",
    "    for article in issueToc.keys():\n",
    "#         try:\n",
    "        articleSoup = BeautifulSoup(sleep_get(issueToc.get(article).get('href'),\n",
    "                                              headers = headers).content,\n",
    "                                    'lxml').find('div', {'id' : 'articleAbstract'})\n",
    "        issueToc.get(article).update({'abstract' : articleSoup.find('div')\n",
    "                                                              .text\n",
    "                                                              .lower(),\n",
    "                                      'collected' : datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')})\n",
    "#         except:\n",
    "#             issueToc.get(article).update({'abstract' : str()})\n",
    "    #\n",
    "    # Return the issue table of contents.\n",
    "    return issueToc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue Vol 11, No 1 success, 5 articles at 20-03-07, 083350Z\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'smj_volumes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2ed0496f7425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/bizMgtStrat.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         json.dump(smj_volumes, \n\u001b[0m\u001b[1;32m     11\u001b[0m                   \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   \u001b[0mensure_ascii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smj_volumes' is not defined"
     ]
    }
   ],
   "source": [
    "for issue in volIssue.keys():\n",
    "    issueUrl = volIssue.get(issue).get('href')\n",
    "    issueToc = getIssueToc(issueUrl)\n",
    "    volIssue.get(issue).update({'issueToC' : issueToc})\n",
    "    print('Issue {} success, {} articles at {}'\\\n",
    "          .format(issue,\n",
    "                  len(issueToc),\n",
    "                  datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "    with io.open('../data/bizMgtStrat.json', 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(volIssue, \n",
    "                  f, \n",
    "                  ensure_ascii = False, \n",
    "                  indent = 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue = np.random.choice(a = list(volIssue.keys()),\n",
    "#                          size = 1).item(0)\n",
    "issueUrl = volIssue.get(issue).get('href')\n",
    "print(f'Issue : {issue}\\nURL : {issueUrl}')\n",
    "issueSoup = BeautifulSoup(sleep_get(volIssue.get(issue).get('href'),\n",
    "                                    headers = headers).content,\n",
    "                          'lxml').find('div', {'id' : 'content'})\n",
    "issueToc = dict(enumerate([{'title' : article.find('a')\n",
    "                                             .text\n",
    "                                             .lower(),\n",
    "                  'href' : article.find('a')\n",
    "                                  .attrs\n",
    "                                  .get('href'),\n",
    "                  'pubDate' : issueSoup.find('div', {'id' : 'issueDescription'})\n",
    "                                       .text\n",
    "                                       .split(', ')[-1]\n",
    "                                       .split('\\\\')[0]}\n",
    "                    for article in issueSoup.find_all('div', {'class' : 'tocTitle'})]))\n",
    "# article = np.random.choice(a = list(issueToc.keys()),\n",
    "#                            size = 1).item(0)\n",
    "articleUrl = issueToc.get(article).get('href')\n",
    "print('Article : {}\\nURL : {}'\\\n",
    "      .format(issueToc.get(article).get('title'),\n",
    "              issueToc.get(article).get('href')))\n",
    "articleSoup = BeautifulSoup(sleep_get(articleUrl,\n",
    "                                      headers = headers).content,\n",
    "                            'lxml').find('div', {'id' : 'articleAbstract'})\n",
    "issueToc.get(article).update({'abstract' :articleSoup.find('p').get_text(strip = True)\\\n",
    "                                                               .lower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(articleSoup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volIssue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⓵ Obtain the URLs for each volume. These located on the journal's homepage.\n",
    "#    collect this in a dictionary labeled `smj_volumes`.  This is a simple \n",
    "#    nested dictionary of {'volume label ' : {'href' : vol_url}}.\n",
    "#    The vol_url attribute is appended to our smj url to get the\n",
    "#    URL for the issue table of contents.\n",
    "smj_volumes = {issues.find('a').attrs.get('title') : {'href' : issues.find('a').attrs.get('href')}\n",
    "                                                     for issues in smj_soup.find('div', {'class' : \"loi--aside__left\"})\\\n",
    "                                                                           .find_all('li')\n",
    "                                                     if issues.find('a').attrs.get('href') != '#' }\n",
    "\n",
    "def getVolumeIssues(volUrl):\n",
    "    volSoup = BeautifulSoup(sleep_get(volUrl,\n",
    "                                      headers = headers).content,\n",
    "                            'lxml').find('ul', {'class' : 'rlist loi__issues'})\\\n",
    "                                   .find_all('li', {'class' : 'card clearfix'})\n",
    "# issue = volSoup[np.random.choice(a = range(len(volSoup)),\n",
    "#                                  size = 1).item(0)]\n",
    "    return {issue.find('a', {'class' : 'visitable'})\n",
    "                 .text : {'href' : issue.find('a', {'class' : 'visitable'})\\\n",
    "                                       .attrs\\\n",
    "                                       .get('href'),\n",
    "                         'coverDate' : issue.find('span', {'class' : 'cover-date-value'}).text }\n",
    "             for issue in volSoup}\n",
    "# ⓶ Get the issues associated with each volume.\n",
    "for volume in smj_volumes.keys():\n",
    "    smj_volumes.get(volume).update({'issues' : getVolumeIssues(smj_url + smj_volumes.get(volume).get('href'))})\n",
    "    print('{} issues collected, success at {}'.format(volume, \n",
    "                                                      datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume = np.random.choice(a = list(smj_volumes.keys()),\n",
    "#                           size = 1).item(0)\n",
    "# issue = np.random.choice(a = list(smj_volumes.get(volume).get('issues').keys()),\n",
    "#                          size = 1).item(0)\n",
    "# print(f'Volume : {volume},   Issue : {issue}')\n",
    "# issue_url = smj_volumes.get(volume).get('issues').get(issue).get('href')\n",
    "# print('Issue URL : {}'.format(smj_url + issue_url) )\n",
    "\n",
    "# smj_volumes.get(volume).get('issues').get(issue).update({'issueToc' : get_issue_tocs(issue_url)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⓷ Get the tables of contents for each issue of each volumne. We add this to\n",
    "#    our smj_volumes dictionary so that our dictionary look like\n",
    "#      {'volumne label' : {'href' : vol_url,\n",
    "#                          'issues' : {'issue label' : 'issue ToC URL'}}}.\n",
    "#    For compactness of logic, we construct a function `get_issue_tocs`\n",
    "#    to get the actual tables of contents.  We then invoke this attribute \n",
    "#    via dictionary comprehension to get \n",
    "def get_issue_tocs(issue_url):\n",
    "    issue_soup = BeautifulSoup(sleep_get(smj_url + issue_url,\n",
    "                                          headers = headers).content,\n",
    "                               'lxml').find_all('div', {'class' : 'issue-item'})\n",
    "    issueToC = list()\n",
    "    for issue in issue_soup:\n",
    "        try:\n",
    "            issueToC.append({'title' : issue.find('h2').text,\n",
    "                             'pubDate' : issue.find('li', {'class' : 'ePubDate'})\\\n",
    "                                              .find_all('span')\\\n",
    "                                              [1]\\\n",
    "                                              .text,\n",
    "                             'abstractHref' : issue.find('a', {'class' : 'issue-item__title visitable'})\\\n",
    "                                                   .attrs\\\n",
    "                                                   .get('href')})\n",
    "        except:\n",
    "            pass\n",
    "    return dict(zip(map(str, range(len(issueToC))),\n",
    "                    issueToC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for volume in smj_volumes.keys():\n",
    "    for issue in smj_volumes.get(volume).get('issues').keys():\n",
    "        issueDict = smj_volumes.get(volume).get('issues').get(issue)\n",
    "        issue_url = issueDict.get('href')\n",
    "        try:\n",
    "            issueToc = get_issue_tocs(issue_url)\n",
    "            issueDict.update({'issueToC' : issueToc})\n",
    "            print('Volume {}, {} success, {} articles at {}'\\\n",
    "                  .format(volume,\n",
    "                          issue,\n",
    "                          len(issueToc),\n",
    "                          datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "        except:\n",
    "            issueToc = get_issue_tocs(issue_url)\n",
    "            issueDict.update({'issueToC' : dict()})\n",
    "            print('Volume {}, {} failure at {}'\\\n",
    "                  .format(volume,\n",
    "                          issue,\n",
    "                          datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "    with io.open('../data/stratEntrepren.json', 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(smj_volumes, \n",
    "                  f, \n",
    "                  ensure_ascii = False, \n",
    "                  indent = 4)\n",
    "    print('Saved {} to JSON at {}'\\\n",
    "          .format(volume,\n",
    "                  datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smj_volumes.get(volume).get('issues').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = np.random.choice(a = list(smj_volumes.keys()),\n",
    "                          size = 1).item(0)\n",
    "issue = np.random.choice(a = list(smj_volumes.get(volume).get('issues').keys()),\n",
    "                         size = 1).item(0)\n",
    "issueTocDict = smj_volumes.get(volume).get('issues').get(issue).get('issueToC')\n",
    "article = np.random.choice(a = list(issueTocDict.keys()),\n",
    "                           size = 1).item(0)\n",
    "print('Volume : {},   Issue : {},\\nArticle  : {}\\nAbstract URL : {}'\\\n",
    "       .format(volume, \n",
    "               issue, \n",
    "               issueTocDict.get(article).get('title'),\n",
    "               smj_url + issueTocDict.get(article).get('abstractHref')) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "for volume in smj_volumes.keys():\n",
    "    for issue in smj_volumes.get(volume).get('issues').keys():\n",
    "        issueTocDict = smj_volumes.get(volume).get('issues').get(issue).get('issueToC')\n",
    "        for article in issueTocDict.keys():\n",
    "            time.sleep(np.random.uniform(low = 0.75,\n",
    "                                         high = 2.75))\n",
    "            driver.get(smj_url + issueTocDict.get(article).get('abstractHref'))\n",
    "            try: \n",
    "                issueTocDict.get(article).update({'abstract' : \n",
    "                                                      driver.find_element_by_id('section-1-en')\\\n",
    "                                                             .text\\\n",
    "                                                             .lower()\\\n",
    "                                                             .replace('\\n','')\\\n",
    "                                                             .replace('abstract', '')\\\n",
    "                                                             .replace('research summary', ' ')\\\n",
    "                                                             .replace('managerial summary', ' ')})\n",
    "            except:\n",
    "                issueTocDict.get(article).update({'abstract' : str()})\n",
    "            try:\n",
    "                issueTocDict.get(article).update({'keywords' : \n",
    "                                              [keyword.text\n",
    "                                                    for keyword in driver.find_elements_by_class_name('badge-type')]})\n",
    "            except:\n",
    "                issueTocDict.get(article).update({'keywords' : list()})\n",
    "            issueTocDict.get(article).update({'collected' : datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')})\n",
    "        print('Volume {}, {} success, {} articles at {}'\\\n",
    "              .format(volume,\n",
    "                      issue,\n",
    "                      len(issueTocDict),\n",
    "                      datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "\n",
    "    with io.open('../data/stratEntrepren.json', 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(smj_volumes, \n",
    "                  f, \n",
    "                  ensure_ascii = False, \n",
    "                  indent = 4)\n",
    "    print('Saved {} to JSON at {}'\\\n",
    "          .format(volume,\n",
    "                  datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smj_volumes.get(volume).get('issues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
